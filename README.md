# eye_for_blind
In this capstone project, I created a deep learning model to explain the contents of an image in the form of speech through caption generation with an attention mechanism on the Flickr 8K dataset. The caption generated through the CNN-RNN model has been converted to speech using the Google translate python library.
